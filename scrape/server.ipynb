{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import chromadb\n",
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "from chromadb.config import Settings\n",
    "import os\n",
    "import ast\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "examples = \"\"\n",
    "with open(\"prerequisiteExamples.txt\") as file:\n",
    "    examples = file.read()\n",
    "\n",
    "\n",
    "secret = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=secret)\n",
    "\n",
    "\n",
    "\n",
    "### SCRAPING LIST OF COURSES ###\n",
    "\n",
    "def get_courses(html: bytes):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    div = soup.find('div', class_=re.compile('^w3-row view view-courses-view view-id-courses_view'))\n",
    "    view_content_div = div.find('div', class_=re.compile('view-content'))\n",
    "    child_divs = view_content_div.find_all('div', recursive=False)\n",
    "    courses = []\n",
    "\n",
    "    for child_div in child_divs:\n",
    "        d = {}\n",
    "\n",
    "        try:\n",
    "            # Extract course name\n",
    "            course_name = child_div.find('div', {'aria-label': True}).get_text(strip=True)\n",
    "\n",
    "            # Extract description\n",
    "            description = child_div.find('div', class_='views-field-field-desc').get_text(strip=True)\n",
    "\n",
    "            # Extract prerequisites\n",
    "            prerequisites = child_div.find('span', class_='views-field-field-prerequisite').get_text(strip=True)\n",
    "            prerequisites = f\"{examples}. The following is an unformatted string containing course codes that you will format: {prerequisites[14:]}. Remember, ONLY respond using the given format rules, and nothing else.\",\n",
    "            prerequisites = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prerequisites[0],\n",
    "                    }\n",
    "                ],\n",
    "            )\n",
    "            prerequisites = prerequisites.choices[0].message.content\n",
    "\n",
    "            d[\"name\"] = course_name\n",
    "            d[\"description\"] = description\n",
    "            d[\"prerequisites\"] = prerequisites\n",
    "            courses.append(d)\n",
    "            print(d)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return courses\n",
    "\n",
    "\n",
    "def getHTMLCourses(url: str): \n",
    "    response = requests.get(url) \n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(\"Error getting HTML\")\n",
    "    else:\n",
    "        html = response.content\n",
    "        return get_courses(html)\n",
    "\n",
    "\n",
    "CHUNKS = 1 # Depending on the size of the input data, this number may need to be increased due to batch size limits\n",
    "\n",
    "def create_model(courses):\n",
    "    \n",
    "    chroma_client = chromadb.PersistentClient(settings=Settings(allow_reset=True))\n",
    "    try:\n",
    "        collection =  chroma_client.get_collection(\"vector_earch\")\n",
    "    except: \n",
    "        chroma_client.reset()\n",
    "        collection = chroma_client.create_collection(name=\"vector_search\")\n",
    "\n",
    "    documents = []\n",
    "    metadatas = []\n",
    "    ids = []\n",
    "    id = 1\n",
    "\n",
    "    for course in courses:\n",
    "        documents.append(course[\"description\"])\n",
    "        metadatas.append({'item_id': course[\"name\"], \"prerequisites\": course[\"prerequisites\"]})\n",
    "        ids.append(f'id{id}')\n",
    "        id += 1\n",
    "\n",
    "    t = len(documents) // CHUNKS\n",
    "\n",
    "    for i in range(0, len(documents), t):\n",
    "        collection.add(\n",
    "            documents=documents[i:i+t],\n",
    "            metadatas=metadatas[i:i+t],\n",
    "            ids=ids[i:i+t]\n",
    "    )\n",
    "    \n",
    "\n",
    "def query_courses(query: str):\n",
    "    chroma_client = chromadb.PersistentClient(settings=Settings(allow_reset=True))\n",
    "    collection =  chroma_client.get_collection(\"vector_search\")\n",
    "    n = 10\n",
    "    results = collection.query(\n",
    "        query_texts=[query],\n",
    "        n_results=n\n",
    "    )\n",
    "\n",
    "    return [{\"name\": results[\"metadatas\"][0][i][\"item_id\"], \"description\": results[\"documents\"][0][i], \"prerequisites\": results[\"metadatas\"][0][i][\"prerequisites\"]} for i in range(0, n)]\n",
    "\n",
    "def search_db(name: str, courses_db):\n",
    "    for course in courses_db:\n",
    "        if course[\"name\"][:8] == name:\n",
    "            return ast.literal_eval(course[\"prerequisites\"])\n",
    "    return []\n",
    "\n",
    "\n",
    "def get_full_trajectory(query, courses_db):\n",
    "    lst = []\n",
    "    interest_courses = query_courses(query)\n",
    "    for course in interest_courses:\n",
    "        lst.append(course[\"name\"][:8])\n",
    "    return get_prereqs(lst, courses_db)\n",
    "\n",
    "\n",
    "def get_prereqs(courses, courses_db):\n",
    "    d = {}\n",
    "    for course in courses:\n",
    "        prereqs = search_db(course, courses_db)\n",
    "        d[course] = get_prereqs(prereqs, courses_db)\n",
    "            \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, abort, request, session\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.secret_key = 'Pathway'\n",
    "\n",
    "@app.route(\"/set_courses\", methods=[\"POST\"])\n",
    "def set_courses():\n",
    "    program_type = request.form.get('program_type')\n",
    "    session['courses'] = getHTMLCourses(f'https://utm.calendar.utoronto.ca/section/{program_type}')\n",
    "    return \"Success\"\n",
    "\n",
    "@app.route(\"/get_courses\", methods=[\"GET\"])\n",
    "def get_crsz():\n",
    "    try:\n",
    "        return session['courses']\n",
    "    except:\n",
    "        abort(500)\n",
    "    \n",
    "\n",
    "@app.route(\"/set_collection\", methods=[\"POST\"])\n",
    "def set_collection():\n",
    "    create_model(session['courses'])\n",
    "    return \"Success\"\n",
    "\n",
    "@app.route(\"/interest_query\", methods=[\"POST\"])\n",
    "def interest_query():\n",
    "    interest_query = request.form.get('query')\n",
    "    print(interest_query)\n",
    "    return query_courses(interest_query)\n",
    "\n",
    "@app.route(\"/interest_timeline\", methods=[\"POST\"])\n",
    "def interest_timeline():\n",
    "    interest_query = request.form.get('query')\n",
    "    return get_full_trajectory(interest_query, session['courses'])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=5328)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
